{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c91be290-ffab-4028-92d4-3841537b15d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /projectnb/ivc-ml/gitika/conda/cs505project/lib/python3.8/site-packages (4.36.2)\n",
      "Requirement already satisfied: filelock in /projectnb/ivc-ml/gitika/conda/cs505project/lib/python3.8/site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /projectnb/ivc-ml/gitika/conda/cs505project/lib/python3.8/site-packages (from transformers) (0.20.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /projectnb/ivc-ml/gitika/conda/cs505project/lib/python3.8/site-packages (from transformers) (1.24.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /projectnb/ivc-ml/gitika/conda/cs505project/lib/python3.8/site-packages (from transformers) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /projectnb/ivc-ml/gitika/conda/cs505project/lib/python3.8/site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /projectnb/ivc-ml/gitika/conda/cs505project/lib/python3.8/site-packages (from transformers) (2023.10.3)\n",
      "Requirement already satisfied: requests in /projectnb/ivc-ml/gitika/conda/cs505project/lib/python3.8/site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /projectnb/ivc-ml/gitika/conda/cs505project/lib/python3.8/site-packages (from transformers) (0.15.0)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /projectnb/ivc-ml/gitika/conda/cs505project/lib/python3.8/site-packages (from transformers) (0.4.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /projectnb/ivc-ml/gitika/conda/cs505project/lib/python3.8/site-packages (from transformers) (4.66.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /projectnb/ivc-ml/gitika/conda/cs505project/lib/python3.8/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2023.12.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /projectnb/ivc-ml/gitika/conda/cs505project/lib/python3.8/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.7.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /projectnb/ivc-ml/gitika/conda/cs505project/lib/python3.8/site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /projectnb/ivc-ml/gitika/conda/cs505project/lib/python3.8/site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /projectnb/ivc-ml/gitika/conda/cs505project/lib/python3.8/site-packages (from requests->transformers) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /projectnb/ivc-ml/gitika/conda/cs505project/lib/python3.8/site-packages (from requests->transformers) (2023.11.17)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e9ef43e9-435c-47e5-8710-08e34ba0d653",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import torch\n",
    "from transformers import BertTokenizer, BertForMaskedLM, AdamW\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1c0c2675-0ac1-49bf-ab68-b4a774dadd04",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = './project_data/preprocessed_data_no_stemming'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8002e376-0f31-40a8-8206-02da927fed83",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "for filename in os.listdir(data_path):\n",
    "    if filename.endswith(\".json\"):\n",
    "        file_path = os.path.join(data_path, filename)\n",
    "\n",
    "        with open(file_path, 'r') as file:\n",
    "            try:\n",
    "                file_content = json.load(file)\n",
    "                data.append(file_content)\n",
    "            except json.JSONDecodeError as e:\n",
    "                print(f\"Error decoding JSON in {filename}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fac30480-b3fc-4dc4-9724-a3cb68cfbb18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc1e77d7cb404d8c96af39fbdfc82f46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1d7cdbb29c64ccb9fc37c650ca0950e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63f14274f17d4ae485f8d56bff6cf07f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3086af87199c44639912d223dca0200b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "tokenized_data = tokenizer([entry[\"Text\"] for entry in data], padding=True, truncation=True, return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "00912574-8cc4-48ec-bc7d-1c9a75116808",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, tokenized_data):\n",
    "        self.tokenized_data = tokenized_data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.tokenized_data[\"input_ids\"])\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            \"input_ids\": self.tokenized_data[\"input_ids\"][idx],\n",
    "            \"attention_mask\": self.tokenized_data[\"attention_mask\"][idx],\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "23318595-4910-446f-96f4-f381e9844f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "train_dataset = CustomDataset(tokenized_data)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6596f92f-d542-4171-9bf7-0d2beabad913",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f86a8795-2564-4889-ba43-198400c777ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'cls.seq_relationship.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "model = BertForMaskedLM.from_pretrained(\"bert-base-uncased\").to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9e6919c2-de39-498b-b3ac-e6bd1ba54d28",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/projectnb/ivc-ml/gitika/conda/cs505project/lib/python3.8/site-packages/transformers/optimization.py:429: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "optimizer = AdamW(model.parameters(), lr=1e-5)\n",
    "num_epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "222c42c0-fad9-4487-ad93-8fb6083f8117",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Average Loss: 3.3473904728889465\n",
      "Epoch 2/10, Average Loss: 2.3742774054408073\n",
      "Epoch 3/10, Average Loss: 2.443785432726145\n",
      "Epoch 4/10, Average Loss: 1.7449168507009745\n",
      "Epoch 5/10, Average Loss: 1.6066503562033176\n",
      "Epoch 6/10, Average Loss: 1.5360700190067291\n",
      "Epoch 7/10, Average Loss: 1.3808880764991045\n",
      "Epoch 8/10, Average Loss: 1.1825059354305267\n",
      "Epoch 9/10, Average Loss: 1.0938133597373962\n",
      "Epoch 10/10, Average Loss: 0.9913296401500702\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for batch in train_loader:\n",
    "        input_ids = batch[\"input_ids\"].to(device)\n",
    "        attention_mask = batch[\"attention_mask\"].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(input_ids, attention_mask=attention_mask, labels=input_ids)\n",
    "        loss = outputs.loss\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    average_loss = total_loss / len(train_loader)\n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs}, Average Loss: {average_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "aa818c6f-3d56-4ef4-a78a-09b6e68dc785",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Sentence: america is europe africa asia europe oceania oceania asia oceania africa oceania australia oceania americas americas asia americas africa americas south america north america central west asia america south asia southeast asia pacific southwest pacific asia asia southwest asia arctic asia central east pacific south pacific arctic north asia africa arctic central america northeast asia northeast pacific pacific central asia northwest pacific northwest southwest southeast southeast siberia northeast southwest siberia alaska arctic siberia arctic siberian northeast arctic northeast central north arctic arctic southeast siberian arctic northwest northwest central pacific alaska southwest alaska siberian siberian siberia siberian northwest siberian\n",
      "Generated Sentence: america is america... america america americas americas... americas europe americas european asia europe asia asia pacific asia oceania africa oceania tropical asia tropical africa tropical oceania oceania arctic tropical geographic regions geographical regions tropical regions arctic region tropical region arctic arctic temperate pacific region temperate region oceania temperate regions antarctic regions southern region antarctic region region regions polar region polar regions maritime regions regions temperate arctic regional arctic regions region regional regions asiatic regions geographic region maritime region geographic geographical region alpine arctic polar arctic geographic arctic geographical geographical geographic regional geographic geographic polar regional polar\n",
      "Generated Sentence: america is africa and asia europe and australia are oceania australia and africa is oceania asia oceania and oceania oceania were africa are africa was africa australia became asia australia was australia becomes oceania became africa asia becomes asia became oceania becomes africa becomes americas became americas becomes asian becomes became africans becomes african becomes africans ▪⁰⁰ oceanianesianesia becomes─⁰nesia africans australianesia oceaniarasia becomes⁰ africans− africans oceania africans africansnesia ▪ oceania ▪nesia⁰ands⁰─¬⁰space africans⁰ᴰ⁰∨⁰ aquitaine\n",
      "Generated Sentence: america is everywhere and everywhere everywhere, everywhere anywhere is anywhere everywhere somewhere somewhere everywhere is everywhere wherever somewhere wherever is wherever wherever someplace is somewhere someplace wherever was wherever anywhere was someplace someplace whenever someplace somewhere inhabited someplace inhabited wherever whenever wherever else wherever existed someplace anywhere someplace or wherever inhabited inhabited somewhere anywhere inhabited anytime wherever occupied wherever otherwise inhabited occupied someplace occupied inhabited anywhere wherever indefinite inhabited uninhabited inhabited whenever inhabited settled inhabited ʰ inhabited otherwise wherever uninhabited anywhere anywhere occupied anywhere otherwise occupied somewhere otherwise otherwise someplace uninhabited wherever ʰ occupied uninhabited someplace otherwise\n",
      "Generated Sentence: america is africa ; europe is africa and asia oceania is asia and oceania ; africa australia asia is the arctic arctic and arctic regions ; arctic is arcticographic andographic regions and regions arctic ranges arctic region arctic antarctic region region inuit regions regional and geographical ranges regions inuit region regions polar regions regions geographical regions cartographic region geographic regions geographic region northern regions region polar regionographic geographic geographic geographical region geographical geographic boundaries geographical geographical arctic geographical inuit geographic area arctic pale geographicographic geographical maritime region antarctic arctic geographic arctic inuit arctic\n"
     ]
    }
   ],
   "source": [
    "num_sentences = 5\n",
    "\n",
    "for _ in range(num_sentences):\n",
    "    prompt = \"America is\"  # You can choose a seed sentence\n",
    "    input_ids = tokenizer.encode(prompt, return_tensors=\"pt\").to(device)\n",
    "\n",
    "    # Generate a sequence of tokens\n",
    "    with torch.no_grad():\n",
    "        output = model.generate(input_ids, max_length=100, num_beams=5, no_repeat_ngram_size=2, top_k=50, top_p=0.95)\n",
    "\n",
    "    # Decode the generated sequence and print the result\n",
    "    generated_sentence = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "    print(\"Generated Sentence:\", generated_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6edd7bfc-e5a3-4901-80b4-454c0570e28d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:cs505project] *",
   "language": "python",
   "name": "conda-env-cs505project-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
