{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iTMzAt5ExQpF",
        "outputId": "f43ff3b8-826d-4088-8ab5-37a31526cdd1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import os\n",
        "import time\n",
        "import datetime\n",
        "from google.colab import drive\n",
        "\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "import nltk\n",
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jPrxpEI4xzfO",
        "outputId": "d71070a7-6d65-4044-f054-723f539ce331"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "print(os.getcwd())\n",
        "os.chdir(\"/content/drive/My Drive/CS505-Project/gpt2-outputs\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IZ7JPIGHx1z2",
        "outputId": "37f9486b-f7a4-424d-8f8e-244778104cd1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/CS505-Project/data/combined_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "files = os.listdir(os.getcwd())\n",
        "files"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YGcz-ccP2puR",
        "outputId": "8650acdd-1e97-4695-9dcc-2bbdacb528cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['gen_abe.txt',\n",
              " 'gen_obama.txt',\n",
              " 'gen_trump.txt',\n",
              " 'gen_wc.txt',\n",
              " 'gen_hitler.txt',\n",
              " 'gen_biden.txt',\n",
              " 'gen_kennedy.txt',\n",
              " 'gen_washington.txt',\n",
              " 'gen_hillary.txt']"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import defaultdict\n",
        "outputs = defaultdict()\n",
        "for i in files:\n",
        "  with open(i, \"r\") as f:\n",
        "    outputs[i.split(\"_\")[1].split(\".\")[0]]=f.read()"
      ],
      "metadata": {
        "id": "Vf8du4sfyA33"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Getting ground truth\n",
        "\n",
        "import json\n",
        "\n",
        "gt=defaultdict(list)\n",
        "print(os.getcwd())\n",
        "os.chdir(\"../data/combined_data\")\n",
        "\n",
        "for json_file in os.listdir():\n",
        "      with open(json_file, \"r\") as f:\n",
        "        temp = []\n",
        "        all = json.load(f)\n",
        "        if type(all) is list:\n",
        "          for i in all:\n",
        "            temp.append(i['Text'])\n",
        "          gt[json_file.split(\".\")[0]] = temp[:5]\n",
        "        elif 'Items' in all:\n",
        "          for i in all['Items']:\n",
        "            temp.append(i['transcript'])\n",
        "          gt[json_file.split(\".\")[0]] = temp[:5]\n",
        "        elif 'speeches' in all:\n",
        "          for i in all['speeches']:\n",
        "            temp.append(i['transcript'])\n",
        "          gt[json_file.split(\".\")[0]] = temp[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J-6qh3OH3abf",
        "outputId": "acde6677-3a97-4df0-de57-38d128b90b85"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/My Drive/CS505-Project/gpt2-outputs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gt.keys()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OgoEwW5D6u1P",
        "outputId": "c548a217-ab12-4742-8bf4-71ab53beb904"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['washington', 'kennedy', 'biden', 'hitler', 'abe', 'wc', 'hillary', 'obama', 'trump'])"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(gt['abe'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OnaKeUfk7utn",
        "outputId": "807d6221-64c7-44bf-aecf-7f57f0482bc0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for key in gt:\n",
        "  gt[key] = \" \".join(gt[key])"
      ],
      "metadata": {
        "id": "RxxfbzOW70pI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gt.keys()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vhJNGxv1879O",
        "outputId": "61e6776c-69f4-4c39-8793-19befd3f87a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['washington', 'kennedy', 'biden', 'hitler', 'abe', 'wc', 'hillary', 'obama', 'trump'])"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Evaluation Metrics\n",
        "\n",
        "1. Cosine Similarity"
      ],
      "metadata": {
        "id": "XgUFWJU09VxZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "import re\n",
        "from collections import Counter\n",
        "\n",
        "WORD = re.compile(r\"\\w+\")\n",
        "\n",
        "\n",
        "def get_cosine(vec1, vec2):\n",
        "    intersection = set(vec1.keys()) & set(vec2.keys())\n",
        "    numerator = sum([vec1[x] * vec2[x] for x in intersection])\n",
        "\n",
        "    sum1 = sum([vec1[x] ** 2 for x in list(vec1.keys())])\n",
        "    sum2 = sum([vec2[x] ** 2 for x in list(vec2.keys())])\n",
        "    denominator = math.sqrt(sum1) * math.sqrt(sum2)\n",
        "\n",
        "    if not denominator:\n",
        "        return 0.0\n",
        "    else:\n",
        "        return float(numerator) / denominator\n",
        "\n",
        "\n",
        "def text_to_vector(text):\n",
        "    words = WORD.findall(text)\n",
        "    return Counter(words)"
      ],
      "metadata": {
        "id": "gGNMpgNR9VPf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for key in gt:\n",
        "  text1 = gt[key]\n",
        "  text2 = outputs[key]\n",
        "\n",
        "  vector1 = text_to_vector(text1)\n",
        "  vector2 = text_to_vector(text2)\n",
        "\n",
        "  cosine = get_cosine(vector1, vector2)\n",
        "\n",
        "  print(f\"Cosine Similarity of generated {key} text ={cosine}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c-RwL11L9n6t",
        "outputId": "97e7a6b4-64bd-44b3-84a3-61a2dc283556"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cosine Similarity of generated washington text =0.9865454097570104\n",
            "Cosine Similarity of generated kennedy text =0.9732442770880877\n",
            "Cosine Similarity of generated biden text =0.9528666579841972\n",
            "Cosine Similarity of generated hitler text =0.9761071484951617\n",
            "Cosine Similarity of generated abe text =0.9767988023758633\n",
            "Cosine Similarity of generated wc text =0.9810289209027907\n",
            "Cosine Similarity of generated hillary text =0.9619610966234926\n",
            "Cosine Similarity of generated obama text =0.9639489525120548\n",
            "Cosine Similarity of generated trump text =0.9578613758426511\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. BLEU Score"
      ],
      "metadata": {
        "id": "ur_Yn_Mw_nD-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "\n",
        "for key in gt:\n",
        "\n",
        "  list_of_references=[]\n",
        "  list_of_hypotheses=[]\n",
        "\n",
        "  list_of_references.append(gt[key].split()) # list of references for all sentences in corpus.\n",
        "  list_of_hypotheses.append(outputs[key].split()) # list of hypotheses that corresponds to list of references.\n",
        "\n",
        "  bleu = nltk.translate.bleu_score.corpus_bleu(list_of_references, list_of_hypotheses)\n",
        "  print(f\"BLEU Score of generated {key} text ={bleu}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KUJQrtaC_mSV",
        "outputId": "2e31dde3-c674-45b6-e294-aa9b5aa06888"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
            "The hypothesis contains 0 counts of 2-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
            "The hypothesis contains 0 counts of 3-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
            "The hypothesis contains 0 counts of 4-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BLEU Score of generated washington text =3.626178001439019e-232\n",
            "BLEU Score of generated kennedy text =5.176857472917499e-156\n",
            "BLEU Score of generated biden text =5.7644671367713944e-232\n",
            "BLEU Score of generated hitler text =4.857652242153452e-232\n",
            "BLEU Score of generated abe text =4.671265459790935e-232\n",
            "BLEU Score of generated wc text =3.792346690660694e-232\n",
            "BLEU Score of generated hillary text =5.3146296728277966e-232\n",
            "BLEU Score of generated obama text =4.8451938810320765e-232\n",
            "BLEU Score of generated trump text =4.8544115075475724e-232\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. ROUGE Score"
      ],
      "metadata": {
        "id": "AL5IJXtuDIm9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install evaluate\n",
        "!pip install rouge-score"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ovwNBN0CDH9r",
        "outputId": "16644c30-f954-4ad3-dbd5-0995e72013c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting evaluate\n",
            "  Downloading evaluate-0.4.1-py3-none-any.whl (84 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting datasets>=2.0.0 (from evaluate)\n",
            "  Downloading datasets-2.16.0-py3-none-any.whl (507 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m507.1/507.1 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from evaluate) (1.23.5)\n",
            "Collecting dill (from evaluate)\n",
            "  Downloading dill-0.3.7-py3-none-any.whl (115 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from evaluate) (1.5.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from evaluate) (4.66.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from evaluate) (3.4.1)\n",
            "Collecting multiprocess (from evaluate)\n",
            "  Downloading multiprocess-0.70.15-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]>=2021.05.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2023.6.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.19.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from evaluate) (23.2)\n",
            "Collecting responses<0.19 (from evaluate)\n",
            "  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (3.13.1)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (10.0.1)\n",
            "Collecting pyarrow-hotfix (from datasets>=2.0.0->evaluate)\n",
            "  Downloading pyarrow_hotfix-0.6-py3-none-any.whl (7.9 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (3.9.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (6.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2023.11.17)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2023.3.post1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.9.4)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.4.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->evaluate) (1.16.0)\n",
            "Installing collected packages: pyarrow-hotfix, dill, responses, multiprocess, datasets, evaluate\n",
            "Successfully installed datasets-2.16.0 dill-0.3.7 evaluate-0.4.1 multiprocess-0.70.15 pyarrow-hotfix-0.6 responses-0.18.0\n",
            "Collecting rouge-score\n",
            "  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from rouge-score) (1.4.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from rouge-score) (3.8.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from rouge-score) (1.23.5)\n",
            "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from rouge-score) (1.16.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->rouge-score) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->rouge-score) (1.3.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk->rouge-score) (2023.6.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk->rouge-score) (4.66.1)\n",
            "Building wheels for collected packages: rouge-score\n",
            "  Building wheel for rouge-score (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for rouge-score: filename=rouge_score-0.1.2-py3-none-any.whl size=24933 sha256=8cc682d88c4c4fb83572cf66b782f0ad147589d413ca3d0464671a77388be60c\n",
            "  Stored in directory: /root/.cache/pip/wheels/5f/dd/89/461065a73be61a532ff8599a28e9beef17985c9e9c31e541b4\n",
            "Successfully built rouge-score\n",
            "Installing collected packages: rouge-score\n",
            "Successfully installed rouge-score-0.1.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import evaluate\n",
        "rouge = evaluate.load('rouge')\n",
        "\n",
        "for key in gt:\n",
        "\n",
        "  list_of_references=[gt[key]] # list of references for all sentences in corpus.\n",
        "  list_of_hypotheses=[outputs[key]] # list of hypotheses that corresponds to list of references.\n",
        "  # print(list_of_hypotheses)\n",
        "  results = rouge.compute(predictions=list_of_hypotheses, references=list_of_references)\n",
        "  print(f\"ROUGE Scores of generated {key} text ={results}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SSoYXB-2DKXS",
        "outputId": "53a3d5e2-729f-4865-e154-aa312e63d74a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROUGE Scores of generated washington text ={'rouge1': 0.7745311818578282, 'rouge2': 0.3173391494002181, 'rougeL': 0.20606192760575665, 'rougeLsum': 0.6332315743567379}\n",
            "ROUGE Scores of generated kennedy text ={'rouge1': 0.24552928607924196, 'rouge2': 0.1460491475821062, 'rougeL': 0.0946630126805704, 'rougeLsum': 0.22778577732361005}\n",
            "ROUGE Scores of generated biden text ={'rouge1': 0.12161490121614903, 'rouge2': 0.09305059456526653, 'rougeL': 0.0581400605814006, 'rougeLsum': 0.11944482119444823}\n",
            "ROUGE Scores of generated hitler text ={'rouge1': 0.14403583883864016, 'rouge2': 0.10315592480222305, 'rougeL': 0.06481612747738807, 'rougeLsum': 0.06481612747738807}\n",
            "ROUGE Scores of generated abe text ={'rouge1': 0.16015192277259058, 'rouge2': 0.11413920805241667, 'rougeL': 0.0698844753916759, 'rougeLsum': 0.0698844753916759}\n",
            "ROUGE Scores of generated wc text ={'rouge1': 0.2861094208109753, 'rouge2': 0.16863070539419087, 'rougeL': 0.10731869226088399, 'rougeLsum': 0.10731869226088399}\n",
            "ROUGE Scores of generated hillary text ={'rouge1': 0.2103386809269162, 'rouge2': 0.14644085063033235, 'rougeL': 0.08352431881843647, 'rougeLsum': 0.08352431881843647}\n",
            "ROUGE Scores of generated obama text ={'rouge1': 0.21887070075409232, 'rouge2': 0.1258200993316574, 'rougeL': 0.08301146465575378, 'rougeLsum': 0.08301146465575378}\n",
            "ROUGE Scores of generated trump text ={'rouge1': 0.11991673481525536, 'rouge2': 0.09754646840148698, 'rougeL': 0.05672440710727827, 'rougeLsum': 0.05672440710727827}\n"
          ]
        }
      ]
    }
  ]
}