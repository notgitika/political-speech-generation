{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gU0eBlW3u1-T"
      },
      "outputs": [],
      "source": [
        "# TOPICS - 33\n",
        "# abstention, accountability, agricultural policy, civil protection,\n",
        "# corruption, culture, debt, democracy, economy, education, elections,\n",
        "# employment, energy, entrepreneurship, environment, external affairs,\n",
        "# health, human rights, housing, infrastructure, justice, labor, media,\n",
        "# migration, national security, pandemic, pensioners, privatization,\n",
        "# public sector, social state, transparency, tourism, other\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import json\n",
        "\n",
        "president_json_file = '/content/drive/MyDrive/project_data/preprocessed_data_no_stemming/Copy of hitler_preprocessed2.json'\n",
        "\n",
        "with open(president_json_file, 'r') as f:\n",
        "  json_str = f.read()\n",
        "\n",
        "data = json.loads(json_str)\n",
        "df = pd.DataFrame(columns = ['Text'])\n",
        "number_of_transcripts = len(data['Items'])\n",
        "for i in range(number_of_transcripts):\n",
        "  #store in csv as a different record for each transcript\n",
        "  df.loc[len(df)] = [data['Items'][i]['transcript']]\n",
        "\n",
        "data_text = df[['Text']]\n",
        "data_text['index'] = data_text.index\n",
        "documents = data_text"
      ],
      "metadata": {
        "id": "q4eLTHZuvS_J"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Preprocessing"
      ],
      "metadata": {
        "id": "SrKl9aaLwJSh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gensim\n",
        "from gensim.utils import simple_preprocess\n",
        "from gensim.parsing.preprocessing import STOPWORDS\n",
        "from nltk.stem import WordNetLemmatizer, SnowballStemmer\n",
        "from nltk.stem.porter import *\n",
        "import numpy as np\n",
        "np.random.seed(2018)"
      ],
      "metadata": {
        "id": "a2YLhPWTwPWO"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('wordnet')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yiq33IcawUsJ",
        "outputId": "83c2bb4c-e3c3-4120-bfdd-74207c9ca45e"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stemmer = SnowballStemmer('english')\n",
        "def lemmatize_stemming(text):\n",
        "    return stemmer.stem(WordNetLemmatizer().lemmatize(text, pos='v'))\n",
        "\n",
        "def preprocess(text):\n",
        "    result = []\n",
        "    for token in gensim.utils.simple_preprocess(text):\n",
        "        if token not in gensim.parsing.preprocessing.STOPWORDS and len(token) > 3:\n",
        "            result.append(lemmatize_stemming(token))\n",
        "    return result"
      ],
      "metadata": {
        "id": "w0wTVYblwaOI"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "processed_docs = documents['Text'].map(preprocess)"
      ],
      "metadata": {
        "id": "JTY3kkjcwlKH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for doc in processed_docs:\n",
        "  print(doc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J7qftLYk3s7-",
        "outputId": "12641d8f-5320-4c04-a8ff-d2e07dbba8a8"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "45\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### BOW"
      ],
      "metadata": {
        "id": "nr6g5lumzyVb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dictionary = gensim.corpora.Dictionary(processed_docs)"
      ],
      "metadata": {
        "id": "ccAsSTh5wvl7"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "count = 0\n",
        "for k, v in dictionary.iteritems():\n",
        "    print(k, v)\n",
        "    count += 1\n",
        "    if count > 10:\n",
        "        break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Jn8BkPJz2Oc",
        "outputId": "6ad82e47-be75-4fdc-9445-254fa26f7c73"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 abandon\n",
            "1 absenc\n",
            "2 accept\n",
            "3 accompani\n",
            "4 accord\n",
            "5 add\n",
            "6 administr\n",
            "7 advanc\n",
            "8 advantag\n",
            "9 alli\n",
            "10 america\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dictionary.filter_extremes(no_below=15, no_above=0.5, keep_n=100000)"
      ],
      "metadata": {
        "id": "4xyMvaXGz7ic"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bow_corpus = [dictionary.doc2bow(doc) for doc in processed_docs]\n",
        "bow_corpus[43]"
      ],
      "metadata": {
        "id": "nQfmVbmQ0A-Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example\n",
        "bow_doc_43 = bow_corpus[43]\n",
        "\n",
        "for i in range(len(bow_doc_43)):\n",
        "    print(\"Word {} (\\\"{}\\\") appears {} time.\".format(bow_doc_43[i][0],\n",
        "                                                     dictionary[bow_doc_43[i][0]],\n",
        "                                                     bow_doc_43[i][1]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lqlFuL-I0IM8",
        "outputId": "84f01731-9f82-49ee-aba3-82782408ab0e"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Word 1 (\"alli\") appears 1 time.\n",
            "Word 2 (\"answer\") appears 1 time.\n",
            "Word 4 (\"asia\") appears 4 time.\n",
            "Word 5 (\"attempt\") appears 1 time.\n",
            "Word 6 (\"away\") appears 2 time.\n",
            "Word 8 (\"better\") appears 1 time.\n",
            "Word 9 (\"command\") appears 3 time.\n",
            "Word 10 (\"communism\") appears 2 time.\n",
            "Word 11 (\"communiti\") appears 1 time.\n",
            "Word 13 (\"courag\") appears 1 time.\n",
            "Word 14 (\"decid\") appears 1 time.\n",
            "Word 15 (\"dedic\") appears 1 time.\n",
            "Word 22 (\"event\") appears 3 time.\n",
            "Word 23 (\"expect\") appears 1 time.\n",
            "Word 25 (\"fail\") appears 1 time.\n",
            "Word 29 (\"germani\") appears 1 time.\n",
            "Word 30 (\"globe\") appears 7 time.\n",
            "Word 32 (\"heavi\") appears 1 time.\n",
            "Word 33 (\"hour\") appears 2 time.\n",
            "Word 34 (\"independ\") appears 2 time.\n",
            "Word 38 (\"involv\") appears 6 time.\n",
            "Word 39 (\"ladi\") appears 1 time.\n",
            "Word 40 (\"latin\") appears 1 time.\n",
            "Word 43 (\"longer\") appears 1 time.\n",
            "Word 44 (\"lose\") appears 2 time.\n",
            "Word 47 (\"missil\") appears 1 time.\n",
            "Word 48 (\"natur\") appears 4 time.\n",
            "Word 50 (\"nuclear\") appears 2 time.\n",
            "Word 54 (\"prevent\") appears 3 time.\n",
            "Word 55 (\"real\") appears 4 time.\n",
            "Word 56 (\"recent\") appears 3 time.\n",
            "Word 58 (\"report\") appears 1 time.\n",
            "Word 62 (\"small\") appears 1 time.\n",
            "Word 63 (\"spread\") appears 1 time.\n",
            "Word 64 (\"surviv\") appears 2 time.\n",
            "Word 69 (\"women\") appears 2 time.\n",
            "Word 70 (\"young\") appears 3 time.\n",
            "Word 72 (\"abl\") appears 2 time.\n",
            "Word 73 (\"abroad\") appears 1 time.\n",
            "Word 76 (\"adopt\") appears 2 time.\n",
            "Word 86 (\"burden\") appears 5 time.\n",
            "Word 87 (\"busi\") appears 1 time.\n",
            "Word 91 (\"carri\") appears 2 time.\n",
            "Word 92 (\"case\") appears 1 time.\n",
            "Word 97 (\"condit\") appears 1 time.\n",
            "Word 98 (\"conduct\") appears 1 time.\n",
            "Word 108 (\"desir\") appears 2 time.\n",
            "Word 109 (\"easi\") appears 2 time.\n",
            "Word 111 (\"encourag\") appears 2 time.\n",
            "Word 114 (\"exampl\") appears 1 time.\n",
            "Word 119 (\"feel\") appears 3 time.\n",
            "Word 120 (\"field\") appears 1 time.\n",
            "Word 122 (\"fulfil\") appears 1 time.\n",
            "Word 124 (\"growth\") appears 5 time.\n",
            "Word 125 (\"higher\") appears 1 time.\n",
            "Word 126 (\"highest\") appears 1 time.\n",
            "Word 127 (\"immedi\") appears 1 time.\n",
            "Word 132 (\"labor\") appears 1 time.\n",
            "Word 133 (\"leadership\") appears 1 time.\n",
            "Word 135 (\"littl\") appears 4 time.\n",
            "Word 139 (\"modern\") appears 1 time.\n",
            "Word 140 (\"month\") appears 1 time.\n",
            "Word 141 (\"move\") appears 1 time.\n",
            "Word 143 (\"occas\") appears 2 time.\n",
            "Word 145 (\"oper\") appears 1 time.\n",
            "Word 147 (\"pass\") appears 2 time.\n",
            "Word 148 (\"percent\") appears 1 time.\n",
            "Word 152 (\"popul\") appears 4 time.\n",
            "Word 155 (\"principl\") appears 3 time.\n",
            "Word 159 (\"question\") appears 1 time.\n",
            "Word 165 (\"result\") appears 1 time.\n",
            "Word 166 (\"return\") appears 2 time.\n",
            "Word 169 (\"secretari\") appears 1 time.\n",
            "Word 172 (\"simpli\") appears 1 time.\n",
            "Word 174 (\"solut\") appears 1 time.\n",
            "Word 175 (\"solv\") appears 1 time.\n",
            "Word 179 (\"step\") appears 2 time.\n",
            "Word 181 (\"suffici\") appears 2 time.\n",
            "Word 182 (\"technolog\") appears 3 time.\n",
            "Word 183 (\"term\") appears 1 time.\n",
            "Word 186 (\"urg\") appears 1 time.\n",
            "Word 187 (\"valu\") appears 1 time.\n",
            "Word 188 (\"welcom\") appears 2 time.\n",
            "Word 189 (\"write\") appears 1 time.\n",
            "Word 190 (\"break\") appears 1 time.\n",
            "Word 191 (\"centuri\") appears 3 time.\n",
            "Word 194 (\"day\") appears 5 time.\n",
            "Word 197 (\"devot\") appears 1 time.\n",
            "Word 198 (\"diplomat\") appears 2 time.\n",
            "Word 201 (\"enemi\") appears 1 time.\n",
            "Word 204 (\"fear\") appears 1 time.\n",
            "Word 205 (\"hear\") appears 3 time.\n",
            "Word 207 (\"histor\") appears 3 time.\n",
            "Word 208 (\"hop\") appears 1 time.\n",
            "Word 209 (\"invit\") appears 1 time.\n",
            "Word 210 (\"mankind\") appears 1 time.\n",
            "Word 211 (\"oppos\") appears 1 time.\n",
            "Word 213 (\"poverti\") appears 1 time.\n",
            "Word 214 (\"rememb\") appears 2 time.\n",
            "Word 216 (\"succeed\") appears 3 time.\n",
            "Word 218 (\"talent\") appears 2 time.\n",
            "Word 219 (\"tell\") appears 1 time.\n",
            "Word 220 (\"washington\") appears 7 time.\n",
            "Word 222 (\"white\") appears 3 time.\n",
            "Word 223 (\"word\") appears 1 time.\n",
            "Word 227 (\"see\") appears 2 time.\n",
            "Word 231 (\"allianc\") appears 3 time.\n",
            "Word 232 (\"decad\") appears 1 time.\n",
            "Word 233 (\"distinguish\") appears 1 time.\n",
            "Word 237 (\"frontier\") appears 1 time.\n",
            "Word 238 (\"generat\") appears 2 time.\n",
            "Word 239 (\"greatest\") appears 2 time.\n",
            "Word 240 (\"john\") appears 1 time.\n",
            "Word 242 (\"moment\") appears 2 time.\n",
            "Word 243 (\"near\") appears 1 time.\n",
            "Word 246 (\"soviet\") appears 3 time.\n",
            "Word 247 (\"start\") appears 1 time.\n",
            "Word 248 (\"thing\") appears 1 time.\n",
            "Word 249 (\"tide\") appears 2 time.\n",
            "Word 250 (\"treati\") appears 1 time.\n",
            "Word 252 (\"war\") appears 1 time.\n",
            "Word 253 (\"western\") appears 2 time.\n",
            "Word 254 (\"children\") appears 2 time.\n",
            "Word 255 (\"ignor\") appears 1 time.\n",
            "Word 257 (\"senat\") appears 4 time.\n",
            "Word 260 (\"vote\") appears 1 time.\n",
            "Word 261 (\"adversari\") appears 2 time.\n",
            "Word 262 (\"affair\") appears 3 time.\n",
            "Word 268 (\"crisi\") appears 1 time.\n",
            "Word 269 (\"destroy\") appears 4 time.\n",
            "Word 271 (\"emerg\") appears 2 time.\n",
            "Word 272 (\"faith\") appears 3 time.\n",
            "Word 275 (\"hazard\") appears 1 time.\n",
            "Word 277 (\"preserv\") appears 2 time.\n",
            "Word 278 (\"proud\") appears 2 time.\n",
            "Word 280 (\"threaten\") appears 1 time.\n",
            "Word 283 (\"destruct\") appears 1 time.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### TF-IDF"
      ],
      "metadata": {
        "id": "e7msJ2Gu0XJo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim import corpora, models\n",
        "\n",
        "tfidf = models.TfidfModel(bow_corpus)"
      ],
      "metadata": {
        "id": "nebiFi6r0OOh"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corpus_tfidf = tfidf[bow_corpus]"
      ],
      "metadata": {
        "id": "LwxBtHBv0azy"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Running LDA with BOW model"
      ],
      "metadata": {
        "id": "gEX6b0Vh0jgd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lda_model = gensim.models.LdaMulticore(bow_corpus, num_topics=32, id2word=dictionary, passes=10, workers=2)"
      ],
      "metadata": {
        "id": "HTSyUgH10dtT"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for idx, topic in lda_model.print_topics(10): # all topics returned ordered by significance\n",
        "    print('Topic: {} \\nWords: {}'.format(idx, topic))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MLDWZ0rG0oZl",
        "outputId": "dc092a9d-6aa7-4984-b2a5-6bdb2d37ba4f"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Topic: 18 \n",
            "Words: 0.073*\"treati\" + 0.050*\"abroad\" + 0.049*\"nuclear\" + 0.044*\"allow\" + 0.035*\"vice\" + 0.035*\"suggest\" + 0.032*\"disarma\" + 0.029*\"question\" + 0.028*\"number\" + 0.028*\"subject\"\n",
            "Topic: 25 \n",
            "Words: 0.079*\"univers\" + 0.030*\"honor\" + 0.025*\"learn\" + 0.023*\"student\" + 0.018*\"talent\" + 0.017*\"institut\" + 0.017*\"write\" + 0.016*\"contribut\" + 0.016*\"person\" + 0.015*\"women\"\n",
            "Topic: 1 \n",
            "Words: 0.133*\"berlin\" + 0.033*\"germani\" + 0.031*\"threat\" + 0.030*\"disarma\" + 0.029*\"soviet\" + 0.028*\"citi\" + 0.024*\"crisi\" + 0.021*\"negoti\" + 0.019*\"longer\" + 0.018*\"propos\"\n",
            "Topic: 29 \n",
            "Words: 0.004*\"berlin\" + 0.004*\"nuclear\" + 0.004*\"senat\" + 0.004*\"independ\" + 0.004*\"latin\" + 0.004*\"question\" + 0.004*\"growth\" + 0.004*\"major\" + 0.004*\"billion\" + 0.004*\"improv\"\n",
            "Topic: 31 \n",
            "Words: 0.038*\"citi\" + 0.038*\"decad\" + 0.025*\"intend\" + 0.019*\"nuclear\" + 0.019*\"month\" + 0.019*\"week\" + 0.019*\"expect\" + 0.019*\"growth\" + 0.019*\"choos\" + 0.019*\"ignor\"\n",
            "Topic: 2 \n",
            "Words: 0.060*\"fight\" + 0.043*\"involv\" + 0.038*\"command\" + 0.038*\"day\" + 0.027*\"nuclear\" + 0.022*\"ahead\" + 0.016*\"period\" + 0.016*\"feel\" + 0.016*\"role\" + 0.016*\"train\"\n",
            "Topic: 12 \n",
            "Words: 0.047*\"surviv\" + 0.043*\"intend\" + 0.042*\"fail\" + 0.031*\"globe\" + 0.028*\"expect\" + 0.026*\"peril\" + 0.026*\"small\" + 0.018*\"inform\" + 0.018*\"record\" + 0.018*\"attempt\"\n",
            "Topic: 23 \n",
            "Words: 0.055*\"frontier\" + 0.043*\"parti\" + 0.038*\"vote\" + 0.026*\"tell\" + 0.021*\"courag\" + 0.021*\"leadership\" + 0.021*\"pressur\" + 0.018*\"senat\" + 0.017*\"young\" + 0.017*\"afford\"\n",
            "Topic: 21 \n",
            "Words: 0.032*\"vice\" + 0.032*\"press\" + 0.032*\"use\" + 0.032*\"major\" + 0.031*\"courag\" + 0.031*\"call\" + 0.031*\"feder\" + 0.031*\"afford\" + 0.030*\"expand\" + 0.030*\"express\"\n",
            "Topic: 3 \n",
            "Words: 0.081*\"labor\" + 0.036*\"billion\" + 0.036*\"trade\" + 0.036*\"western\" + 0.024*\"abroad\" + 0.024*\"employ\" + 0.021*\"economi\" + 0.021*\"month\" + 0.021*\"pass\" + 0.018*\"abl\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Performance evaluation for LDA with BOW"
      ],
      "metadata": {
        "id": "zlt76AQJ1HR8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for index, score in sorted(lda_model[bow_corpus[40]], key=lambda tup: -1*tup[1]):\n",
        "    print(\"\\nScore: {}\\t \\nTopic: {}\".format(score, lda_model.print_topic(index, 20)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6SQNNyoD1LXn",
        "outputId": "e9afa0c0-49ed-4aeb-d165-e85019b07b57"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Score: 0.7672661542892456\t \n",
            "Topic: 0.014*\"nuclear\" + 0.012*\"growth\" + 0.011*\"allianc\" + 0.011*\"billion\" + 0.011*\"economi\" + 0.010*\"cooper\" + 0.010*\"improv\" + 0.010*\"independ\" + 0.010*\"month\" + 0.010*\"alli\" + 0.009*\"social\" + 0.009*\"capac\" + 0.009*\"product\" + 0.009*\"soviet\" + 0.009*\"step\" + 0.008*\"propos\" + 0.008*\"latin\" + 0.008*\"expand\" + 0.008*\"hop\" + 0.008*\"measur\"\n",
            "\n",
            "Score: 0.20850178599357605\t \n",
            "Topic: 0.123*\"nuclear\" + 0.084*\"treati\" + 0.052*\"arm\" + 0.051*\"soviet\" + 0.035*\"step\" + 0.027*\"agreement\" + 0.026*\"risk\" + 0.020*\"small\" + 0.019*\"disarma\" + 0.017*\"conduct\" + 0.016*\"debat\" + 0.015*\"destruct\" + 0.013*\"hazard\" + 0.013*\"threat\" + 0.013*\"mankind\" + 0.013*\"berlin\" + 0.013*\"produc\" + 0.012*\"prevent\" + 0.012*\"spread\" + 0.011*\"destroy\"\n",
            "\n",
            "Score: 0.018662666901946068\t \n",
            "Topic: 0.074*\"senat\" + 0.049*\"question\" + 0.028*\"vice\" + 0.024*\"vote\" + 0.018*\"suggest\" + 0.015*\"soviet\" + 0.015*\"latin\" + 0.014*\"move\" + 0.013*\"parti\" + 0.013*\"ahead\" + 0.012*\"major\" + 0.012*\"growth\" + 0.012*\"feder\" + 0.011*\"thing\" + 0.010*\"economi\" + 0.010*\"record\" + 0.010*\"africa\" + 0.010*\"agre\" + 0.010*\"elect\" + 0.010*\"better\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Performance evaluation on generated text"
      ],
      "metadata": {
        "id": "cHw9nsq15cQP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "output_text_file = '/content/drive/MyDrive/gpt2_outputs/gen_hitler.text'\n",
        "with open(output_text_file, 'r') as f:\n",
        "  output_text = f.read()\n",
        "\n",
        "# USING BOW\n",
        "bow_vector = dictionary.doc2bow(preprocess(unseen_document))\n",
        "\n",
        "for index, score in sorted(lda_model[bow_vector], key=lambda tup: -1*tup[1]):\n",
        "    print(\"Topic:\")\n",
        "    print(\"Score: {}\\t Topic: {}\".format(score, lda_model.print_topic(index, 5)))"
      ],
      "metadata": {
        "id": "ct_5ovDf6AZo"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}